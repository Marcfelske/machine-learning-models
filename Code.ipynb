{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb-x3HwpZXG7"
   },
   "source": [
    "# ML Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12254,
     "status": "ok",
     "timestamp": 1582889890587,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "JReW8VggNtIj",
    "outputId": "ca2356d8-aa91-431a-9657-0fa8db58ae92"
   },
   "outputs": [],
   "source": [
    "run_in = 'colab'\n",
    "# run_in = 'local'\n",
    "# run_in = 'colab&gsheets'\n",
    "\n",
    "if run_in == 'local':\n",
    "    import os\n",
    "    import math\n",
    "    from collections import Counter\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import scipy.stats as ss\n",
    "    import matplotlib.pyplot as plt\n",
    "    !pip install scikit-learn\n",
    "    import sklearn.preprocessing as sp\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    from subprocess import check_output\n",
    "\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from dython.nominal import conditional_entropy\n",
    "    from dython.nominal import theils_u\n",
    "    from dython.nominal import associations\n",
    "\n",
    "    from sklearn.metrics import make_scorer\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    # from sklearn.preprocessing import LabelEncoder\n",
    "    # labelencoder = LabelEncoder()\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    class color:\n",
    "      PURPLE = '\\033[95m'\n",
    "      CYAN = '\\033[96m'\n",
    "      DARKCYAN = '\\033[36m'\n",
    "      BLUE = '\\033[94m'\n",
    "      GREEN = '\\033[92m'\n",
    "      YELLOW = '\\033[93m'\n",
    "      RED = '\\033[91m'\n",
    "      BOLD = '\\033[1m'\n",
    "      UNDERLINE = '\\033[4m'\n",
    "      END = '\\033[0m'\n",
    "\n",
    "    import pprint\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "    #for CramersV\n",
    "    from dython._private import (convert, remove_incomplete_samples, replace_nan_with_value)\n",
    "    REPLACE = 'replace'\n",
    "    DROP = 'drop'\n",
    "    DROP_SAMPLES = 'drop_samples'\n",
    "    DROP_FEATURES = 'drop_features'\n",
    "    SKIP = 'skip'\n",
    "    DEFAULT_REPLACE_VALUE = 0.0\n",
    "    \n",
    "if run_in == 'colab' or run_in == 'colab&gsheets':  \n",
    "    import os\n",
    "    import math\n",
    "    from collections import Counter\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import scipy.stats as ss\n",
    "    import matplotlib.pyplot as plt\n",
    "    !pip install scikit-learn\n",
    "    # https://github.com/shakedzy/dython/blob/master/dython/nominal.py\n",
    "    !pip install dython\n",
    "    from dython.nominal import conditional_entropy\n",
    "    from dython.nominal import theils_u\n",
    "    from dython.nominal import associations\n",
    "    \n",
    "    import sklearn.preprocessing as sp\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "    from subprocess import check_output\n",
    "\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "    from sklearn.metrics import make_scorer\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    # from sklearn.preprocessing import LabelEncoder\n",
    "    # labelencoder = LabelEncoder()\n",
    "\n",
    "    import itertools\n",
    "    \n",
    "    class color:\n",
    "      PURPLE = '\\033[95m'\n",
    "      CYAN = '\\033[96m'\n",
    "      DARKCYAN = '\\033[36m'\n",
    "      BLUE = '\\033[94m'\n",
    "      GREEN = '\\033[92m'\n",
    "      YELLOW = '\\033[93m'\n",
    "      RED = '\\033[91m'\n",
    "      BOLD = '\\033[1m'\n",
    "      UNDERLINE = '\\033[4m'\n",
    "      END = '\\033[0m'\n",
    "\n",
    "    import pprint\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "    #for CramersV\n",
    "    from dython._private import (convert, remove_incomplete_samples, replace_nan_with_value)\n",
    "    REPLACE = 'replace'\n",
    "    DROP = 'drop'\n",
    "    DROP_SAMPLES = 'drop_samples'\n",
    "    DROP_FEATURES = 'drop_features'\n",
    "    SKIP = 'skip'\n",
    "    DEFAULT_REPLACE_VALUE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33624,
     "status": "ok",
     "timestamp": 1582889911989,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "caGh1YQ1OD_E",
    "outputId": "db0acb55-887f-4160-ccce-03ca93f85f74"
   },
   "outputs": [],
   "source": [
    "if run_in == 'local':\n",
    " base_path = '/Users/timbeck/Downloads/'\n",
    "\n",
    "if run_in == 'colab':  \n",
    "  base_path = '/content/drive/My Drive/USERNAME/Analysis' # for google cloud\n",
    "  # base_path = '/content/drive/My Drive/USERNAMEMLattempt/' # for google cloud USERNAME\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "if run_in == 'colab&gsheets':  \n",
    "  base_path = '/content/drive/My Drive/Colab Notebooks/' # for google sheets\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "  import gspread\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "  gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
    "\n",
    "print('base_path set to:')\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36747,
     "status": "ok",
     "timestamp": 1582889915143,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "o15bP0ncb4dc",
    "outputId": "d8cf219b-22ae-47dc-be4b-ef415ecba51e"
   },
   "outputs": [],
   "source": [
    "os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhEPHzG9CBfp"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tO_RdL5jl9b5"
   },
   "outputs": [],
   "source": [
    "def cramers_v(x, y, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE):\n",
    "    \"\"\"\n",
    "    Calculates Cramer's V statistic for categorical-categorical association.\n",
    "    Uses correction from Bergsma and Wicher, Journal of the Korean Statistical\n",
    "    Society 42 (2013): 323-328.\n",
    "    This is a symmetric coefficient: V(x,y) = V(y,x)\n",
    "    Original function taken from: https://stackoverflow.com/a/46498792/5863503\n",
    "    Wikipedia: https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V\n",
    "    **Returns:** float in the range of [0,1]\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list / NumPy ndarray / Pandas Series\n",
    "        A sequence of categorical measurements\n",
    "    y : list / NumPy ndarray / Pandas Series\n",
    "        A sequence of categorical measurements\n",
    "    nan_strategy : string, default = 'replace'\n",
    "        How to handle missing values: can be either 'drop' to remove samples\n",
    "        with missing values, or 'replace' to replace all missing values with\n",
    "        the nan_replace_value. Missing values are None and np.nan.\n",
    "    nan_replace_value : any, default = 0.0\n",
    "        The value used to replace missing values with. Only applicable when\n",
    "        nan_strategy is set to 'replace'.\n",
    "    \"\"\"\n",
    "\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    # print(nan_strategy)\n",
    "    # print(nan_replace_value)\n",
    "\n",
    "    if nan_strategy == REPLACE:\n",
    "        x, y = replace_nan_with_value(x, y, nan_replace_value)\n",
    "\n",
    "        # print(\"NEW X AND Y\")\n",
    "        # print(x)\n",
    "        # print(\"lenx\", len(x))\n",
    "        # print(y)\n",
    "        # print(\"leny\", len(y))\n",
    "\n",
    "    elif nan_strategy == DROP:\n",
    "        x, y = remove_incomplete_samples(x, y)\n",
    "\n",
    "        # print(\"DROP NAN X AND Y\")\n",
    "        # print(\"type x\", type(x))\n",
    "        # print(x)\n",
    "        # print(\"lenx\", len(x))\n",
    "\n",
    "        # print(y)\n",
    "        # print(\"type y\", type(y))\n",
    "        # print(\"leny\", len(y))\n",
    "    \n",
    "    ax = np.asarray(x)\n",
    "    ay = np.asarray(y)\n",
    "\n",
    "    confusion_matrix = pd.crosstab(ax, ay)\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    # print(\"chi2=\", chi2)\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    # print(\"n\",n)\n",
    "    phi2 = chi2 / n\n",
    "    # print(\"phi2=\", phi2)\n",
    "    r, k = confusion_matrix.shape\n",
    "    # print(\"r=\", r)\n",
    "    # print(\"k=\", k)\n",
    "    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "    rcorr = r - ((r - 1)**2) / (n - 1)\n",
    "    kcorr = k - ((k - 1)**2) / (n - 1)\n",
    "    # print(\"rcorr=\", rcorr)\n",
    "    # print(\"kcorr=\", kcorr)\n",
    "    c_v = np.sqrt(phi2corr/min((kcorr-1),(rcorr-1)))\n",
    "\n",
    "    #pvalue p_v, with degrees of freedom (rcorr-1)*(kcorr-1)\n",
    "    dof = (rcorr-1)*(kcorr-1)\n",
    "    # print(\"dof\", dof)\n",
    "    p_v = 1 - ss.chi2.cdf(chi2, dof)\n",
    "    \n",
    "    # print(\"c_v=\", c_v)\n",
    "    # print(\"p_v=\", p_v)\n",
    "\n",
    "    return c_v, p_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ATxvsrftinRa"
   },
   "outputs": [],
   "source": [
    "def theils_u(x, y, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE):\n",
    "    \"\"\"\n",
    "    Calculates Theil's U statistic (Uncertainty coefficient) for categorical-\n",
    "    categorical association. This is the uncertainty of x given y: value is\n",
    "    on the range of [0,1] - where 0 means y provides no information about\n",
    "    x, and 1 means y provides full information about x.\n",
    "    This is an asymmetric coefficient: U(x,y) != U(y,x)\n",
    "    Wikipedia: https://en.wikipedia.org/wiki/Uncertainty_coefficient\n",
    "    **Returns:** float in the range of [0,1]\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : list / NumPy ndarray / Pandas Series\n",
    "        A sequence of categorical measurements\n",
    "    y : list / NumPy ndarray / Pandas Series\n",
    "        A sequence of categorical measurements\n",
    "    nan_strategy : string, default = 'replace'\n",
    "        How to handle missing values: can be either 'drop' to remove samples\n",
    "        with missing values, or 'replace' to replace all missing values with\n",
    "        the nan_replace_value. Missing values are None and np.nan.\n",
    "    nan_replace_value : any, default = 0.0\n",
    "        The value used to replace missing values with. Only applicable when\n",
    "        nan_strategy is set to 'replace'.\n",
    "    \"\"\"\n",
    "    if nan_strategy == REPLACE:\n",
    "        x, y = replace_nan_with_value(x, y, nan_replace_value)\n",
    "    elif nan_strategy == DROP:\n",
    "        x, y = remove_incomplete_samples(x, y)\n",
    "    s_xy = conditional_entropy(x, y)\n",
    "    # print(s_xy)\n",
    "    x_counter = Counter(x)\n",
    "    total_occurrences = sum(x_counter.values())\n",
    "    p_x = list(map(lambda n: n / total_occurrences, x_counter.values()))\n",
    "    s_x = ss.entropy(p_x)\n",
    "    if s_x == 0:\n",
    "        t_u = 1\n",
    "    else:\n",
    "        t_u = (s_x - s_xy) / s_x\n",
    "    return t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5ro_Q90iGcM"
   },
   "outputs": [],
   "source": [
    "def interval_documentor(variable,cut_task,bin_names):\n",
    "  variable_intervals = []\n",
    "  number_of_bins = len(cut_task.dtype.categories)\n",
    "  # print(\"number_of_bins\",number_of_bins)\n",
    "  for i in range(0,number_of_bins):\n",
    "    # print(\"list_index\",i)\n",
    "    str_i = str(list(cut_task.dtype.categories)[i])\n",
    "    variable_intervals.append(str_i)\n",
    "  zip_variable_intervals = list(zip(variable_intervals,bin_names))\n",
    "  return zip_variable_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILusUwSybJs-"
   },
   "outputs": [],
   "source": [
    "def half_split(df,x_header_select):\n",
    "  #cuts the data at 0 and makes two groups on each side at 0.5 quantile\n",
    "  df_temp_low = df[df[x_header_select]<0]\n",
    "  df_temp_high = df[df[x_header_select]>=0]\n",
    "  lowest = df_temp_low[x_header_select].min()-1\n",
    "  low_mid = df_temp_low[x_header_select].quantile(0.5)\n",
    "  high_mid = df_temp_high[x_header_select].quantile(0.5)\n",
    "  highest = df_temp_high[x_header_select].max()+1\n",
    "  smaller_than_zero = -0.000000001\n",
    "  generated_bins = [lowest, low_mid, smaller_than_zero, 0, high_mid, highest]\n",
    "  return generated_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icA547nLgoJH"
   },
   "outputs": [],
   "source": [
    "def zero_thirds(df,x_header_select):\n",
    "  #cuts the 0 off and the rest in thirds\n",
    "  df_no_zero = df[df[x_header_select]!=0]\n",
    "  low = df_no_zero[x_header_select].quantile(0.33)\n",
    "  mid = df_no_zero[x_header_select].quantile(0.66)\n",
    "  high = df_no_zero[x_header_select].max()+1\n",
    "  smaller_than_zero = -0.000000001\n",
    "  generated_bins = [smaller_than_zero, 0, low, mid, high]\n",
    "  return generated_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkxvsdlhbW7P"
   },
   "outputs": [],
   "source": [
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    \n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoDTQVfLbqVH"
   },
   "outputs": [],
   "source": [
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # Create a decision tree regressor object\n",
    "    regressor = DecisionTreeRegressor()\n",
    "\n",
    "    # Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'max_depth':[1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    # Make sure to include the right parameters in the object:\n",
    "    # (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n",
    "    grid = GridSearchCV(estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JpVJhPhrWbvF"
   },
   "outputs": [],
   "source": [
    "def cramer_df_selector(df_selected_variable,df_selected_target,save = True):\n",
    "  selected_variables = list(df_selected_variable.columns)\n",
    "  selected_target = list(df_selected_variable.columns)\n",
    "\n",
    "  col_combinations = list(itertools.product(df_selected_variable.columns,df_selected_target.columns))\n",
    "\n",
    "  variable_list = []\n",
    "  target_list = []\n",
    "  c_v_list = []\n",
    "  p_v_list = []\n",
    "  t_u_list = []\n",
    "\n",
    "  for i in col_combinations:\n",
    "    x = df_variables[i[0]]\n",
    "    y = df_targets[i[1]]\n",
    "\n",
    "    c_v, p_v = cramers_v(x, y, nan_strategy = REPLACE, nan_replace_value = DEFAULT_REPLACE_VALUE)\n",
    "    variable = i[0]\n",
    "    target = i[1]\n",
    "\n",
    "    variable_list.append(variable)\n",
    "    target_list.append(target)\n",
    "    c_v_list.append(c_v)\n",
    "    p_v_list.append(p_v)\n",
    "\n",
    "    t_u = theils_u(x, y, nan_strategy = REPLACE, nan_replace_value = DEFAULT_REPLACE_VALUE)\n",
    "    t_u_list.append(t_u)\n",
    "\n",
    "  df_result = pd.DataFrame()\n",
    "  df_result[\"variable\"] = variable_list\n",
    "  df_result[\"target\"] = target_list\n",
    "  df_result[\"c_v\"] = c_v_list\n",
    "  df_result[\"p_v\"] = p_v_list\n",
    "  df_result[\"t_u\"] = t_u_list\n",
    "\n",
    "  # sort out all the c_v values based on the p-value p_v:\n",
    "  df_result_p_vrelevant = df_result[df_result[\"p_v\"]<=0.1]\n",
    "  df_result_p_vrelevant = df_result_p_vrelevant.reset_index(drop=True)\n",
    "  p_v_relevant_headers = [h for h in list(df.columns) if h in list(set(df_result_p_vrelevant[\"variable\"]))]\n",
    "\n",
    "  # sort out all the c_v values based on the association relevance threshold [weak assocation if c_v>0.1]:\n",
    "  df_result_val_and_p_vrelevant = df_result_p_vrelevant[df_result_p_vrelevant[\"c_v\"]>=0.1]\n",
    "  df_result_val_and_p_vrelevant = df_result_val_and_p_vrelevant.reset_index(drop=True)\n",
    "  val_and_p_v_relevant_headers = [h for h in list(df.columns) if h in list(set(df_result_val_and_p_vrelevant[\"variable\"]))]\n",
    "\n",
    "  if save:\n",
    "  # save to excel\n",
    "    with pd.ExcelWriter(os.path.join(base_path,'Twitter_Cramer_Theil_.xlsx')) as writer:\n",
    "      df_result.to_excel(writer, sheet_name= \"Cramer_V_and_Theil_U\", index=True) \n",
    "      df_result_p_vrelevant.to_excel(writer, sheet_name= \"Rel_C_V_and_T_U\", index=True) \n",
    "      df_result_val_and_p_vrelevant.to_excel(writer, sheet_name= \"Rel_val_p_v_C_V_and_T_U\", index=True) \n",
    "\n",
    "  # create the dataframe comprising the determined relevant variables and the selected target:\n",
    "  df_c_v_and_p_v_relevant = df[val_and_p_v_relevant_headers+selected_target]\n",
    "\n",
    "  print(val_and_p_v_relevant_headers)\n",
    "  print(len(val_and_p_v_relevant_headers))\n",
    "\n",
    "  return val_and_p_v_relevant_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8ilvGBkklQw"
   },
   "outputs": [],
   "source": [
    "def ML(df,ML_selected_variables,ML_selected_target,no_iterations):\n",
    "  '''\n",
    "  variables must be a lists\n",
    "  target must be a string\n",
    "  '''\n",
    "  factorized_nw = df[selected_variables+[selected_target]].copy()\n",
    "  for column in factorized_nw.columns.values:\n",
    "      f, _ = pd.factorize(factorized_nw[column])\n",
    "      factorized_nw.loc[:,column] = f\n",
    "  ohe = sp.OneHotEncoder()\n",
    "  X = factorized_nw.drop([selected_target],axis=1)\n",
    "  y = factorized_nw[selected_target].tolist()\n",
    "  ohe.fit(X)\n",
    "  X = ohe.transform(X).toarray()\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "  print(\"selected_target:\", selected_target)\n",
    "  for i in range(1,no_iterations+1):\n",
    "      tree = DecisionTreeClassifier(splitter='best', max_depth=i, random_state=42)\n",
    "      tree.fit(X_train,y_train)\n",
    "      y_pred = tree.predict(X_test)\n",
    "      \n",
    "      print(\"Max depth: {} - accuracy:\".format(i), accuracy_score(y_test, y_pred, normalize=True))\n",
    "      print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfZw8Uz5B0lU"
   },
   "source": [
    "# Create categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41657,
     "status": "ok",
     "timestamp": 1582889920098,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "rSES5bAKIhgQ",
    "outputId": "41059cc6-f0c4-4d3e-af74-eb248aababd5"
   },
   "outputs": [],
   "source": [
    "if run_in == 'colab' or run_in == 'local':\n",
    "  df = pd.read_excel(os.path.join(base_path,\"Data_Prep_Database.xlsx\"), skiprows = 0)\n",
    "\n",
    "df = df.rename(index=str, columns={\"Series A\" : \"Series_A\"})\n",
    "df = df.rename(index=str, columns={\"Series B\" : \"Series_B\"})\n",
    "\n",
    "#exclude columns:\n",
    "selected_target_list = ['dt_avg', 'num_sum_raised_to_date', 'max_post_money_valuation']\n",
    "exclude_sheet_name_variables = ['company_name','founded_date',\"num_company_age_to_today\",'London',  'Cambridge', 'Oxford', 'Bristol', 'Other', \"num_log10_sum_raised_to_date\", \"log10_max_post_money_valuation\",'last_stage_before_survey','last_stage_during_survey','fundraising_cadence','fundraising_cadence_category']\n",
    "sheet_name_variables = [h for h in list(df.columns) if h not in selected_target_list and h not in exclude_sheet_name_variables]\n",
    "df = df[sheet_name_variables + selected_target_list]\n",
    "\n",
    "fill_nan = True\n",
    "give_category_names = True\n",
    "\n",
    "all_variable_interval_description_dict = {}\n",
    "\n",
    "################## To TEST STUFF ##################\n",
    "# df[[\"dt_avg\"]]\n",
    "print(df[\"dt_avg\"].describe())\n",
    "###################################################\n",
    "\n",
    "counter = 0\n",
    "for x_header in list(df.columns):\n",
    "  counter +=1\n",
    "\n",
    "  # ########## TARGETS ############################################################################\n",
    "  # #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  # if x_header == \"dt_avg\":\n",
    "  #   #decide if the final categories should be named or numerical categories:\n",
    "  #   df[x_header] = df[x_header].fillna(-10e6)\n",
    "  #   if give_category_names:\n",
    "  #     bin_labels = [\"X1_NA\",\"1_very_short_dt_avg\",\"2_short_dt_avg\",\"3_long_dt_avg\", \"4_very_long_dt_avg\"]\n",
    "  #   if not give_category_names:\n",
    "  #     bin_labels = quattro\n",
    "  #   #define how we want to cut\n",
    "  #   cut_type = \"cut\"    #cuts with a self defined list\n",
    "  #   # cut_type = \"qcut\" #cuts into q=n n different buckets\n",
    "  \n",
    "  #   if cut_type == \"qcut\": \n",
    "  #     #document cutting:\n",
    "  #     zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "  #     #cut and overwrite:\n",
    "  #     if fill_nan:\n",
    "  #       df[x_header] = df[x_header].fillna(10e4)\n",
    "  #     df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "  #   if cut_type == \"cut\":\n",
    "  #     cut_info = ['Slicing info: Self defined thresholds'] \n",
    "  #     #document cutting:\n",
    "  #     bin_values = [-11e6,-1e-09, 0, 243.3308333333333, 406.43, 1750.0]\n",
    "  #     zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "  #     #cut and overwrite:\n",
    "  #     # if fill_nan:\n",
    "  #       # df[x_header] = df[x_header].fillna(10e4)\n",
    "  #     df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "  #   all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  # #-----------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75502,
     "status": "ok",
     "timestamp": 1582889953980,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "bX1O3biyPL5V",
    "outputId": "bac6b396-e099-4bfd-a7f8-ccf825a1cc9a"
   },
   "outputs": [],
   "source": [
    "if run_in == 'colab' or run_in == 'local':\n",
    "  df = pd.read_excel(os.path.join(base_path,\"Data_Prep_Database.xlsx\"), skiprows = 0)\n",
    "\n",
    "df = df.rename(index=str, columns={\"Series A\" : \"Series_A\"})\n",
    "df = df.rename(index=str, columns={\"Series B\" : \"Series_B\"})\n",
    "\n",
    "#exclude columns:\n",
    "selected_target_list = ['dt_avg', 'num_sum_raised_to_date', 'max_post_money_valuation']\n",
    "exclude_sheet_name_variables = ['company_name','founded_date',\"num_company_age_to_today\",'London',  'Cambridge', 'Oxford', 'Bristol', 'Other', \"num_log10_sum_raised_to_date\", \"log10_max_post_money_valuation\",'last_stage_before_survey','last_stage_during_survey','fundraising_cadence','fundraising_cadence_category']\n",
    "fnf_sna = [h for h in df.columns if \"fnf\" in h]\n",
    "fr_weighted_sna = [h for h in df.columns if \"fr_weighted\" in h]\n",
    "\n",
    "sheet_name_variables = [h for h in list(df.columns) if h not in selected_target_list and h not in exclude_sheet_name_variables and h not in fnf_sna and h not in fr_weighted_sna]\n",
    "df = df[sheet_name_variables + selected_target_list]\n",
    "\n",
    "fill_nan = True\n",
    "give_category_names = True\n",
    "\n",
    "all_variable_interval_description_dict = {}\n",
    "\n",
    "################## To TEST STUFF ##################\n",
    "# # df[[\"fnf_degree_mean\"]]\n",
    "# print(df[\"fnf_degree_mean\"].describe())\n",
    "###################################################\n",
    "\n",
    "counter = 0\n",
    "for x_header in list(df.columns):\n",
    "  counter +=1\n",
    "\n",
    "  ########## TARGETS ############################################################################\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"dt_avg\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].fillna(-10e6)\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"X1_NA\",\"1_pre_inc_dt_avg\",\"2_short_dt_avg\",\"3_medium_dt_avg\", \"4_long_dt_avg\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\"    #cuts with a self defined list\n",
    "    # cut_type = \"qcut\" #cuts into q=n n different buckets\n",
    "  \n",
    "    if cut_type == \"qcut\": \n",
    "      #document cutting:\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(10e4)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [-11e6,-3, 0, 205, 315, 10e6]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(10e4)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"num_sum_raised_to_date\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].fillna(0)\n",
    "    df[x_header] = df[x_header].replace(0, 1)\n",
    "    df[x_header] = np.log10(df[x_header])\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_funding\", \"2_five_figure\", \"3_half_mil\", \"4_six_figure\",\"5_five_mil\", \"6_seven_figure\", \"7_eight_figure_plus\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = [1,2,3,4,5,6,7]\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\"    #cuts with a self defined list\n",
    "    # cut_type = \"qcut\" #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      pass\n",
    "      #document cutting:\n",
    "      # zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [-0.001,5,5.69897000434,6,6.69897000434,7,8,10]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        print(\"fillna happens\")\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"max_post_money_valuation\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].replace(0, 1)\n",
    "    df[x_header] = np.log10(df[x_header])\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_valuation\", \"2_five_figure\", \"3_half_mil\", \"4_six_figure\",\"5_five_mil\", \"6_seven_figure\", \"7_eight_figure_plus\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = [1,2,3,4,5,6,7]\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\"    #cuts with a self defined list\n",
    "    # cut_type = \"qcut\" #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      pass\n",
    "      #document cutting:\n",
    "      # zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [-0.001,5,5.69897000434,6,6.69897000434,7,8,10]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  ########## VARIABLES ############################################################################\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"num_company_age_to_today\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_young_company_age\",\"2_young_company_age\",\"3_mature_company_age\", \"4_very_mature_company_age\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    # cut_type = \"cut\" #cuts with a self defined list\n",
    "    cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\":\n",
    "      cut_info = ['Slicing info: Qartile cut']\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      #document cutting:\n",
    "      bin_values = []\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"inbound_links\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_inbound_links\",\"2_little_inbound_links\",\"3_medium_inbound_links\", \"4_high_inbound_links\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    # cut_type = \"cut\" #cuts with a self defined list\n",
    "    cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\":\n",
    "      cut_info = ['Slicing info: Qartile cut']\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      #document cutting:\n",
    "      bin_values = []\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"global_pagerank\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_good_global_pagerank\",\"2_good_global_pagerank\",\"3_bad_global_pagerank\", \"4_very_bad_global_pagerank\", \"5_no_global_pagerank\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = [1,2,3,4,5]\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\"    #cuts with a self defined list\n",
    "    # cut_type = \"qcut\" #cuts into q=n n different buckets\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(2e7)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [10047.999,2220568,4461287,8317489,19544569,2e7]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(2e7)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"has_twitter\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "\n",
    "  if x_header == \"has_website\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "\n",
    "  if x_header == \"b2b\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "\n",
    "  if x_header == \"had_event\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"tweet_count\":\n",
    "      #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low_num_tweets\",\"2_medium_num_tweets\", \"4_high_num_tweets\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "  \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"tweets_per_day\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low_num_tweets\",\"2_medium_num_tweets\", \"4_high_num_tweets\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "  \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"last_stage_before_survey\":\n",
    "    print(x_header, \"is already categorical\")\n",
    "\n",
    "  if x_header == \"last_stage_during_survey\":\n",
    "    print(x_header, \"is already categorical\")\n",
    "\n",
    "  if x_header == \"fundraising_cadence\":\n",
    "    print(x_header, \"is already categorical\")\n",
    "\n",
    "  if x_header == \"fundraising_cadence_category\":\n",
    "    print(x_header, \"is already categorical\")\n",
    "\n",
    "  if x_header == \"Angel\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "  \n",
    "  if x_header == \"Grant\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "  \n",
    "  if x_header == \"Crowdfunding\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "\n",
    "  if x_header == \"Seed\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "  \n",
    "  if x_header == \"Series_A\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "\n",
    "  if x_header == \"Series_B\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"hq_city_ecosystem\":\n",
    "    print(x_header, \"is already categorical\")  \n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"num_sum_investors\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].fillna(0)\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_investors\",\"2_low_num_investors\", \"3_medium_num_investors\", \"4_high_num_investors\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    \n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "  if x_header == \"num_sum_follow_on_investors\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].fillna(0)\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_foll_investors\",\"2_low_num_foll_investors\", \"3_medium_num_foll_investors\", \"4_high_num_foll_investors\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    \n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"accelerated\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "\n",
    "  if x_header == \"invested\":\n",
    "    df[x_header] = df[x_header].replace(1,True)\n",
    "    df[x_header] = df[x_header].replace(0,False)\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"new_to_followon_investor_ratio\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if fill_nan:\n",
    "      df[x_header] = df[x_header].fillna(-1)\n",
    "    bin_labels = [\"X1_NA\", \"X2_No_investors\", \"1_no_follow_on\",\"2_low_follow_on\", \"3_medium_follow_on\", \"4_high_follow_on\"]\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    \n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = [-2,-0.0001,0,2,3.75,5,20]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(10e7)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "      \n",
    "  if x_header == \"num_rounds\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].fillna(0)\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_foll_investors\",\"2_low_num_foll_investors\", \"3_medium_num_foll_investors\", \"4_high_num_foll_investors\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    \n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "      \n",
    "  if x_header == \"num_unique_rounds\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    df[x_header] = df[x_header].fillna(0)\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_no_foll_investors\",\"2_low_num_foll_investors\", \"3_medium_num_foll_investors\", \"4_high_num_foll_investors\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    \n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"fnf_degree_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    cut_info = ['Slicing info: Qartile cut']\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut'] \n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"fnf_degree_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "  \n",
    "  if x_header == \"fnf_degree_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_degree_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_degree_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_degree_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_degree_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut'] \n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_degree_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_degree_rel_difference\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_degree_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_degree_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_degree_rel_difference\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again'] \n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"fr_weighted_bi_direct_degree_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"fr_weighted_bi_direct_degree_delta_survey\":  \n",
    "  #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "     \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"fr_weighted_bi_direct_degree_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_div_by_friends_degree_ratio\": \n",
    "    if fill_nan:\n",
    "      df[x_header] = df[x_header].fillna(-1)\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    bin_labels = [\"X1_NA\", \"X2_No_friends\", \"1_low_follow_on\", \"2_medium_follow_on\", \"3_high_follow_on\"]\n",
    "    #define how we want to cut\n",
    "    print(df[[x_header]].isnull().sum())\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    \n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = [-2]+zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"c_and_i_betweenness_centrality\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "  \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"c_and_i_eigenvector_centrality\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_max_10_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [-0.001,0,1,2,10]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_max_100_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_max_1000_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_max_10000_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_max_10_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [-0.001,0,1,2,10]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_max_100_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_max_1000_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_max_10000_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"bi_direct_max_10_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = [-0.001,0,1,2,10]\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"bi_direct_max_100_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"bi_direct_max_1000_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"bi_direct_max_10000_matches\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals \n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "  \n",
    "  if x_header == \"ego_followers_density\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      print(bin_values)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      print(zip_variable_intervals)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"ego_friends_density\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      print(bin_values)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      print(zip_variable_intervals)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"ego_bi_direct_density\":  \n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_none\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = cut_info = ['Slicing info: Self defined thresholds'] \n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      print(bin_values)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      print(zip_variable_intervals)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_match_count_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_match_count_delta_survey\":  \n",
    "  #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "     \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values = half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_match_count_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "  \n",
    "  if x_header == \"followers_match_count_per_user\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "  \n",
    "  if x_header == \"followers_match_w_count_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "  \n",
    "  if x_header == \"followers_match_w_count_per_user_avg\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_match_w_count_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"followers_match_w_count_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_count_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_count_delta_survey\":  \n",
    "  #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values = half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_count_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_count_per_user\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_w_count_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_w_count_per_user_avg\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_w_count_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"friends_match_w_count_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_count_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_count_delta_survey\":  \n",
    "  #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values = half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_count_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_count_per_user\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_w_count_mean\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_w_per_user_count_avg\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_very_low\",\"2_low\",\"3_high\", \"4_very_high\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "    \n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\":\n",
    "      cut_info = ['Slicing info: Cut off the \"0\" and split the rest in third cut']\n",
    "      #document cutting:\n",
    "      bin_values = zero_thirds(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_w_count_delta_survey\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined list\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "  if x_header == \"unweighted_bi_direct_match_w_count_rel_difference\":\n",
    "    #decide if the final categories should be named or numerical categories:\n",
    "    if give_category_names:\n",
    "      bin_labels = [\"1_high_loss\",\"2_small_loss\", \"3_true_zero\", \"4_small_gain\", \"5_high_gain\"]\n",
    "    if not give_category_names:\n",
    "      bin_labels = quattro\n",
    "    #define how we want to cut\n",
    "    cut_type = \"cut\" #cuts with a self defined listl\n",
    "    # cut_type = \"qcut\"  #cuts into q=n n different buckets\n",
    "\n",
    "    if cut_type == \"qcut\": \n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.qcut(df[x_header], q=4),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      df[x_header] = pd.qcut(df[x_header], q=len(bin_labels), labels = bin_labels)\n",
    "    if cut_type == \"cut\": \n",
    "      cut_info = ['Slicing info: Half split and split halves again']\n",
    "      #document cutting:\n",
    "      bin_values =  half_split(df,x_header)\n",
    "      zip_variable_intervals = interval_documentor(x_header,pd.cut(df[x_header], bins=bin_values),bin_names=bin_labels)\n",
    "      #cut and overwrite:\n",
    "      if fill_nan:\n",
    "        df[x_header] = df[x_header].fillna(0)\n",
    "      df[x_header] = pd.cut(df[x_header], bins=bin_values, labels = bin_labels)\n",
    "    all_variable_interval_description_dict[x_header] = cut_info + zip_variable_intervals\n",
    "  #-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    print(\"number of nans:\", df[x_header].isnull().sum(axis = 0))\n",
    "    print(df[x_header].describe())\n",
    "    # print(df[x_header].quantile([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]))\n",
    "    print(df[x_header].value_counts())\n",
    "    print(counter, \"of\", len(df.columns))\n",
    "    # pp.pprint(all_variable_interval_description_dict)\n",
    "df.iloc[:10,20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NU4noS_rjEfy"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = \"/ML_categories.json\"\n",
    "\n",
    "with open(base_path + file_name, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_variable_interval_description_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uO7C0hDCU2D"
   },
   "source": [
    "# Post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75472,
     "status": "ok",
     "timestamp": 1582889953981,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "FHOPhz_hwY-b",
    "outputId": "edb8d4f3-ad13-4f82-efe7-72f15c7746f6"
   },
   "outputs": [],
   "source": [
    "nan_cols = [i for i in df.columns if df[i].isnull().any()]\n",
    "if len(nan_cols)>0:\n",
    "  print(\"These columns have 'nan' values:\")\n",
    "  df[nan_cols].isnull().sum()\n",
    "\n",
    "  # Can be used to replace nan values based on other column\n",
    "  # df[\"followers_match_w_count_delta_survey\"] = df.followers_match_w_count_delta_survey[df['has_twitter'] != 0].fillna(0)\n",
    "else:\n",
    "  print(\"There are NO 'nan' values in ANY column!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jW0icm0sQjOC"
   },
   "source": [
    "make columns category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSTVmwTWQlp0"
   },
   "outputs": [],
   "source": [
    "df['has_twitter'] = df.has_twitter.astype('category')\n",
    "df['has_website'] = df.has_website.astype('category')\n",
    "df['b2b'] = df.b2b.astype('category')\n",
    "df['had_event'] = df.had_event.astype('category')\n",
    "df['Angel'] = df.Angel.astype('category')\n",
    "df['Grant'] = df.Grant.astype('category')\n",
    "df['Crowdfunding'] = df.Crowdfunding.astype('category')\n",
    "df['Seed'] = df.Seed.astype('category')\n",
    "df['Series_A'] = df.Series_A.astype('category')\n",
    "df['Series_B'] = df.Series_B.astype('category')\n",
    "df['hq_city_ecosystem'] = df.hq_city_ecosystem.astype('category')\n",
    "df['accelerated'] = df.accelerated.astype('category')\n",
    "df['invested'] = df.invested.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D13bYPtR5wY0"
   },
   "outputs": [],
   "source": [
    "df = df.replace(False, \"No\")\n",
    "df = df.replace(True, \"Yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvaTVcotQpai"
   },
   "source": [
    "Decide which variables to test against target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1322,
     "status": "ok",
     "timestamp": 1582895023920,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "IfmC1SkBUt_-",
    "outputId": "4b158a2b-a7dd-49b4-abab-6aa33f8b92a3"
   },
   "outputs": [],
   "source": [
    "selected_target_candidates = ['dt_avg',\n",
    "                              'num_sum_raised_to_date',\n",
    "                              'max_post_money_valuation',\n",
    "                              'had_event',\n",
    "                              'Angel',\n",
    "                              'Grant',\n",
    "                              'Crowdfunding',\n",
    "                              'Seed',\n",
    "                              'Series_A',\n",
    "                              'Series_B',\n",
    "                              'accelerated',\n",
    "                              'invested',\n",
    "                              'num_rounds',\n",
    "                              'num_unique_rounds',\n",
    "                              'c_and_i_betweenness_centrality',\n",
    "                              'c_and_i_eigenvector_centrality',\n",
    "                              'num_sum_investors',\n",
    "                              'num_sum_follow_on_investors',\n",
    "                              'new_to_followon_investor_ratio']\n",
    "\n",
    "definite_variables = [h for h in list(df.columns) if h not in selected_target_candidates]\n",
    "# pp.pprint(definite_variables)\n",
    "\n",
    "selected_target = 'dt_avg'\n",
    "# selected_target = 'num_sum_raised_to_date'\n",
    "# selected_target = 'max_post_money_valuation'\n",
    "# selected_target = 'had_event'\n",
    "# selected_target = 'Angel'\n",
    "# selected_target = 'Grant'\n",
    "# selected_target = 'Crowdfunding'\n",
    "# selected_target = 'Seed'\n",
    "# selected_target = 'Series_A'\n",
    "# selected_target = 'Series_B'\n",
    "# selected_target = 'accelerated'\n",
    "# selected_target = 'invested'\n",
    "# selected_target = 'num_rounds'\n",
    "# selected_target = 'num_unique_rounds'\n",
    "# selected_target = 'c_and_i_betweenness_centrality'\n",
    "# selected_target = 'c_and_i_eigenvector_centrality'\n",
    "# selected_target = 'num_sum_investors'\n",
    "# selected_target = 'num_sum_follow_on_investors'\n",
    "# selected_target = 'new_to_followon_investor_ratio'\n",
    "\n",
    "if selected_target == \"dt_avg\":\n",
    "  print(\"Target is:\", selected_target)\n",
    "  # put_back_in = ['accelerated','c_and_i_betweenness_centrality','c_and_i_eigenvector_centrality','num_sum_investors','num_sum_follow_on_investors','new_to_followon_investor_ratio']\n",
    "  put_back_in = list(set(['accelerated','new_to_followon_investor_ratio']).difference(set([selected_target])))\n",
    "  variables_based_on_target = definite_variables + put_back_in\n",
    "  print(\"Of reinserted variables of the targets,\", put_back_in)\n",
    "  # to restore the original order:\n",
    "  selected_variables = [h for h in list(df.columns) if h in variables_based_on_target]\n",
    "  # print(selected_variables)\n",
    "  df_variables = df[selected_variables].copy()\n",
    "  df_targets = df[[selected_target]].copy()\n",
    "\n",
    "if selected_target == \"num_sum_raised_to_date\":\n",
    "  print(\"Target is:\", selected_target)\n",
    "  put_back_in = list(set(['accelerated','c_and_i_betweenness_centrality','c_and_i_eigenvector_centrality','num_sum_investors','new_to_followon_investor_ratio','had_event', 'accelerated']).difference(set([selected_target])))\n",
    "  variables_based_on_target = definite_variables + put_back_in\n",
    "  print(\"Of reinserted variables of the targets,\", put_back_in)\n",
    "  # to restore the original order:\n",
    "  selected_variables = [h for h in list(df.columns) if h in variables_based_on_target]\n",
    "  # print(selected_variables)\n",
    "  df_variables = df[selected_variables].copy()\n",
    "  df_targets = df[[selected_target]].copy()\n",
    "\n",
    "if selected_target == \"max_post_money_valuation\":\n",
    "  print(\"Target is:\", selected_target)\n",
    "  put_back_in = list(set(['accelerated','c_and_i_betweenness_centrality','c_and_i_eigenvector_centrality','num_sum_investors','new_to_followon_investor_ratio','had_event', 'accelerated']).difference(set([selected_target])))\n",
    "  variables_based_on_target = definite_variables + put_back_in\n",
    "  print(\"Of reinserted variables of the targets,\", put_back_in)\n",
    "  # to restore the original order:\n",
    "  selected_variables = [h for h in list(df.columns) if h in variables_based_on_target]\n",
    "  # print(selected_variables)\n",
    "  df_variables = df[selected_variables].copy()\n",
    "  df_targets = df[[selected_target]].copy()\n",
    "\n",
    "if selected_target not in ['dt_avg', 'num_sum_raised_to_date', 'max_post_money_valuation']:\n",
    "  print(\"Target is:\", selected_target)\n",
    "  put_back_in = list(set(['accelerated','c_and_i_betweenness_centrality','c_and_i_eigenvector_centrality','num_sum_investors','new_to_followon_investor_ratio','had_event','accelerated']).difference(set([selected_target])))\n",
    "  variables_based_on_target = definite_variables + put_back_in\n",
    "  print(\"Of reinserted variables of the targets,\",put_back_in)\n",
    "  # to restore the original order:\n",
    "  selected_variables = [h for h in list(df.columns) if h in variables_based_on_target]\n",
    "  # print(selected_variables)\n",
    "  df_variables = df[selected_variables].copy()\n",
    "  df_targets = df[[selected_target]].copy()\n",
    "\n",
    "# Show variables that are out:\n",
    "not_in_headers = set(df.columns).difference(set(selected_variables)) \n",
    "# print(\"Variables not in:\", not_in_headers)\n",
    "\n",
    "# Check target not in variables:\n",
    "# if selected_target in df_variables.columns:\n",
    "  # print(\"WARNING, target variable in explaining variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flgFNctAS-ra"
   },
   "outputs": [],
   "source": [
    "# df_variables.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZ0allQ0TCLF"
   },
   "outputs": [],
   "source": [
    "# df_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwWKrzqzSJZc"
   },
   "source": [
    "# Cramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2682,
     "status": "ok",
     "timestamp": 1582895025314,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "i1oMwnW2UkoN",
    "outputId": "0c596659-61fe-4945-9ff9-512447849ec4"
   },
   "outputs": [],
   "source": [
    "cramer_val_and_p_v_relevant_headers = cramer_df_selector(df_variables,df_targets,save=True)\n",
    "# pp.pprint(cramer_val_and_p_v_relevant_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vLDPeM3sWzc"
   },
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uot__f3xiAn2"
   },
   "outputs": [],
   "source": [
    "val_and_p_v_relevant_headers_temp = selected_variables\n",
    "# val_and_p_v_relevant_headers_temp = cramer_val_and_p_v_relevant_headers\n",
    "\n",
    "# val_and_p_v_relevant_headers_temp = [\n",
    "#                                 'inbound_links',\n",
    "#                                 'global_pagerank',\n",
    "#                                 'b2b',\n",
    "#                                 # 'num_sum_investors',\n",
    "#                                 # 'num_sum_follow_on_investors',\n",
    "#                                 'accelerated',\n",
    "#                                 # 'invested',\n",
    "#                                 # 'new_to_followon_investor_ratio',\n",
    "#                                 'fnf_degree_delta_survey',\n",
    "#                                 'fnf_degree_rel_difference',\n",
    "#                                 'friends_degree_delta_survey',\n",
    "#                                 'friends_degree_rel_difference',\n",
    "#                                 'followers_degree_mean',\n",
    "#                                 'followers_degree_delta_survey',\n",
    "#                                 'followers_degree_rel_difference',\n",
    "#                                 'unweighted_bi_direct_degree_delta_survey',\n",
    "#                                 'unweighted_bi_direct_degree_rel_difference',\n",
    "#                                 'fr_weighted_bi_direct_degree_delta_survey',\n",
    "#                                 'followers_div_by_friends_degree_ratio',\n",
    "#                                 # 'c_and_i_betweenness_centrality',\n",
    "#                                 # 'c_and_i_eigenvector_centrality',\n",
    "#                                 'followers_max_1000_matches',\n",
    "#                                 'followers_max_10000_matches',\n",
    "#                                 'friends_max_100_matches',\n",
    "#                                 'bi_direct_max_1000_matches',\n",
    "#                                 'bi_direct_max_10000_matches',\n",
    "#                                 'followers_match_count_mean',\n",
    "#                                 'followers_match_count_delta_survey',\n",
    "#                                 'followers_match_count_rel_difference',\n",
    "#                                 'followers_match_w_count_mean',\n",
    "#                                 'followers_match_w_count_delta_survey',\n",
    "#                                 'followers_match_w_count_rel_difference',\n",
    "#                                 'friends_match_count_delta_survey',\n",
    "#                                 'friends_match_count_rel_difference',\n",
    "#                                 'friends_match_w_count_delta_survey',\n",
    "#                                 'friends_match_w_count_rel_difference',\n",
    "#                                 'unweighted_bi_direct_match_count_delta_survey',\n",
    "#                                 'unweighted_bi_direct_match_count_rel_difference',\n",
    "#                                 'unweighted_bi_direct_match_w_count_delta_survey',\n",
    "#                                 'unweighted_bi_direct_match_w_count_rel_difference'\n",
    "#                                 ]\n",
    "# print(len(val_and_p_v_relevant_headers_temp))\n",
    "\n",
    "# print(val_and_p_v_relevant_headers_temp)\n",
    "# print(selected_target)\n",
    "# ML(df,ML_selected_variables = val_and_p_v_relevant_headers_temp, ML_selected_target = selected_target, no_iterations=10)\n",
    "\n",
    "#headers not in:\n",
    "not_in_headers = set(df.columns).difference(set(selected_variables)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2931,
     "status": "ok",
     "timestamp": 1582895025596,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "CB_cHx_rfoex",
    "outputId": "3c667801-3619-4a68-d5fb-4466c7425d4f"
   },
   "outputs": [],
   "source": [
    "print(\"not in list\", len(not_in_headers), \"elements:\", not_in_headers)\n",
    "print(\"list\", len(val_and_p_v_relevant_headers_temp), \"elements:\", val_and_p_v_relevant_headers_temp)\n",
    "factorized_nw = df[val_and_p_v_relevant_headers_temp].copy()\n",
    "for column in factorized_nw.columns.values:\n",
    "    f, _ = pd.factorize(factorized_nw[column])\n",
    "    factorized_nw.loc[:,column] = f\n",
    "ohe = sp.OneHotEncoder()\n",
    "X = factorized_nw\n",
    "# unique_labels = list(df.dt_avg.unique())\n",
    "unique_labels = list(df[selected_target].unique())\n",
    "# y = [unique_labels.index(i) for i in df.dt_avg.values]\n",
    "y = [unique_labels.index(i) for i in df[selected_target].values]\n",
    "\n",
    "ohe.fit(X)\n",
    "X_plot = X.copy()\n",
    "#X = ohe.transform(X).toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"selected_target:\", selected_target)\n",
    "for i in range(1,10):\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=42)\n",
    "    tree.fit(X_train,y_train)\n",
    "    y_pred = tree.predict(X_test)\n",
    "    \n",
    "    print(\"Max depth: {} - accuracy:\".format(i), accuracy_score(y_test, y_pred, normalize=True))\n",
    "    print()\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EGP84nphqV9"
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth=2, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2898,
     "status": "ok",
     "timestamp": 1582895025597,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "_kEI69Mhhqth",
    "outputId": "870d2bd1-c8de-4551-ade0-cd5f7ff9da70"
   },
   "outputs": [],
   "source": [
    "print(\"not in list\", len(not_in_headers), \"elements:\", not_in_headers)\n",
    "print(\"list\", len(val_and_p_v_relevant_headers_temp), \"elements:\", val_and_p_v_relevant_headers_temp)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IkMAPuYKj7hz"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "          \"objective\" : \"multiclass\",\n",
    "          \"num_class\" : len(unique_labels),\n",
    "          \"num_leaves\" : 60,\n",
    "          \"max_depth\": -1,\n",
    "          \"learning_rate\" : 0.01,\n",
    "          \"bagging_fraction\" : 0.9,  # subsample\n",
    "          \"feature_fraction\" : 0.9,  # colsample_bytree\n",
    "          \"bagging_freq\" : 5,        # subsample_freq\n",
    "          \"bagging_seed\" : 2018,\n",
    "          \"verbosity\" : -1\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3085,
     "status": "ok",
     "timestamp": 1582895025817,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "8auHZiA_J9MP",
    "outputId": "147eefbb-1d60-453d-ab17-ba0b454a360f"
   },
   "outputs": [],
   "source": [
    "print(unique_labels)\n",
    "\n",
    "print(len(X_train))\n",
    "\n",
    "splitsize_val= round(0.7*len(X_train))\n",
    "print(splitsize_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4489,
     "status": "ok",
     "timestamp": 1582895027252,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "yqroVE67j7h0",
    "outputId": "5dc7d1e5-e0fe-4da1-f4e9-71400495655e"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "splitsize_val= round(0.7*len(X_train))\n",
    "print(splitsize_val)\n",
    "lgtrain, lgval = lgb.Dataset(X_train[0:splitsize_val], y_train[0:splitsize_val]), lgb.Dataset(X_train[splitsize_val:], y_train[splitsize_val:])\n",
    "# lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)\n",
    "lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2ebYwB_j7h2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = lgbmodel.predict(X_test)\n",
    "y_pred = [np.argmax(pred) for pred in y_pred] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4458,
     "status": "ok",
     "timestamp": 1582895027253,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "yJI7srB-j7h3",
    "outputId": "f1c88830-160d-443f-e062-60c3d8898ee5"
   },
   "outputs": [],
   "source": [
    "print(\"not in list\", len(not_in_headers), \"elements:\", not_in_headers)\n",
    "print(\"list\", len(val_and_p_v_relevant_headers_temp), \"elements:\", val_and_p_v_relevant_headers_temp)\n",
    "\n",
    "print(\"Max depth: {} - accuracy:\".format(i), accuracy_score(y_test, y_pred, normalize=True))\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6697,
     "status": "ok",
     "timestamp": 1582895029523,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "SP1zngEfaaVN",
    "outputId": "1741f61a-80ac-42f2-822d-e2cf2b49b46f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\n",
    "feature_imp_split = pd.DataFrame(sorted(zip(lgbmodel.feature_importance(importance_type='split'), X_plot.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp_split.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig('lgbm_importances-01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8355,
     "status": "ok",
     "timestamp": 1582895031212,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "XPR-l2U74VSE",
    "outputId": "044154bb-24f7-43d5-fb3b-2f3fc52724ed"
   },
   "outputs": [],
   "source": [
    "feature_imp_gain = pd.DataFrame(sorted(zip(lgbmodel.feature_importance(importance_type='gain'), X_plot.columns)), columns=['Value','Feature'])\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp_gain.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izZuJIt-7kuX"
   },
   "outputs": [],
   "source": [
    "df_feature_importance_split = feature_imp_split.sort_values(by=\"Value\", ascending=False)\n",
    "df_feature_importance_split[\"norm_feature_imp\"] = df_feature_importance_split[['Value']].mul(100).div(df_feature_importance_split[['Value']].max()).round(1)\n",
    "\n",
    "df_feature_importance_gain = feature_imp_gain.sort_values(by=\"Value\", ascending=False)\n",
    "df_feature_importance_gain[\"norm_feature_imp\"] = df_feature_importance_gain[['Value']].mul(100).div(df_feature_importance_gain[['Value']].max()).round(1)\n",
    "\n",
    "# save to excel\n",
    "with pd.ExcelWriter(os.path.join(base_path, \"feature-importance/\" + selected_target + '_feature_importance.xlsx')) as writer:\n",
    "  df_feature_importance_split.to_excel(writer, sheet_name= \"split\" , index=True)\n",
    "  df_feature_importance_gain.to_excel(writer, sheet_name= \"gain\" , index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8321,
     "status": "ok",
     "timestamp": 1582895031212,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "sF7nDZra-WQf",
    "outputId": "a5264cbb-3066-4c98-df15-3871e6320681"
   },
   "outputs": [],
   "source": [
    "df_feature_importance_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8499,
     "status": "ok",
     "timestamp": 1582895031424,
     "user": {
      "displayName": "DISPLAYNAME",
      "photoUrl": "PHOTOURL",
      "userId": "USERID"
     },
     "user_tz": 0
    },
    "id": "72vLHoM1Q9Rr",
    "outputId": "4a9fb44e-a297-486b-c8b2-861a2cf22d0c"
   },
   "outputs": [],
   "source": [
    "df_feature_importance_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxMYTr9t414m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2020-02-27 GoogleML Twitter Study Cramer and Theil.ipynb",
   "provenance": [
    {
     "file_id": "11rToXulmGKq6mgTdURQbg71DeWx6lpl_",
     "timestamp": 1581856109556
    },
    {
     "file_id": "1NofQK1RDn_g_1UtJxlg0bYcA_bNPyvHE",
     "timestamp": 1581449096154
    },
    {
     "file_id": "1lgcjHyGFMlYvpUP2KaYuDAc4i3Dazg0k",
     "timestamp": 1581356408332
    },
    {
     "file_id": "14Xtys7PiKoaWQHaVtZRWEomAhCV-5Byo",
     "timestamp": 1581291297917
    },
    {
     "file_id": "1FTf-oFiLBKs9-UDsgCBzkbk77U5f3pOQ",
     "timestamp": 1581263763073
    },
    {
     "file_id": "10X_HmFVqGsF63eueNxq63TBw8X7ftAz5",
     "timestamp": 1581247069521
    },
    {
     "file_id": "1VCXQ-6VVleK-ykrbw8_ydSTigMKLP_-G",
     "timestamp": 1581201421761
    },
    {
     "file_id": "18x80CGtcehmESVVPJ4A0JEIpwxmKdEeV",
     "timestamp": 1581195058796
    },
    {
     "file_id": "1mFSfjydT0Bxu0vQpymY5YoRuKWwTNqk7",
     "timestamp": 1577568185187
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
